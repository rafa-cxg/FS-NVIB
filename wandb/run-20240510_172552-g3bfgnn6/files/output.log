Not using distributed mode
Namespace(batch_size=1, num_classes=1000, epochs=100, fp16=False, output_dir='outputs/original_diet_small_lr1e-4', device='cuda:0', seed=0, data_path='/datasets01/imagenet_full_size/061417/', pretrained_checkpoint_path='.', dataset='mini_imagenet', nClsEpisode=5, nSupport=5, nQuery=15, nValEpisode=120, nEpisode=2000, image_size=128, base_sources=['aircraft', 'cu_birds', 'dtd', 'fungi', 'ilsvrc_2012', 'omniglot', 'quickdraw', 'vgg_flower'], val_sources=['aircraft', 'cu_birds', 'dtd', 'fungi', 'ilsvrc_2012', 'omniglot', 'quickdraw', 'vgg_flower'], test_sources=['traffic_sign', 'mscoco', 'ilsvrc_2012', 'omniglot', 'aircraft', 'cu_birds', 'dtd', 'quickdraw', 'fungi', 'vgg_flower'], shuffle=True, train_transforms=['random_resized_crop', 'jitter', 'random_flip', 'to_tensor', 'normalize'], test_transforms=['resize', 'center_crop', 'to_tensor', 'normalize'], num_ways=None, num_support=None, num_query=None, min_ways=5, max_ways_upper_bound=50, max_num_query=10, max_support_set_size=500, max_support_size_contrib_per_class=100, min_examples_in_class=0, min_log_weight=-0.6931471805599453, max_log_weight=0.6931471805599453, ignore_bilevel_ontology=False, ignore_dag_ontology=False, ignore_hierarchy_probability=0.0, test_n_way=5, n_shot=5, cdfsl_domains=['EuroSAT', 'ISIC', 'CropDisease', 'ChestX'], arch='deit_small_patch16', patch_size=16, pretrained_weights='', checkpoint_key='teacher', unused_params=False, no_pretrain=False, deploy='vanilla', num_adapters=1, ada_steps=40, ada_lr=0.05, aug_prob=0.9, aug_types=['color', 'translation'], img_size=224, drop=0.0, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.05, sched='cosine', lr=1e-06, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.0, train_interpolation='bicubic', repeated_aug=False, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.0, cutmix=0.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', teacher_model='regnety_160', teacher_path='', distillation_type='none', distillation_alpha=0.5, distillation_tau=1.0, resume='', start_epoch=0, eval=False, dist_eval=False, num_workers=10, pin_mem=True, world_size=1, dist_url='env://', nvib=True, delta=1.0, alpha_tau=0.0, stdev_tau=0.0, lambda_klg=0.001, lambda_kld=0.001, nvib_layers=[0, 1, 2, 3, 4, 5, 6], distributed=False)
Creating model: ProtoNet deit_small_patch16
Using NVIB Vision Transformer
Layer 0 has nvib_layer
Layer 1 has nvib_layer
Layer 2 has nvib_layer
Layer 3 has nvib_layer
Layer 4 has nvib_layer
Layer 5 has nvib_layer
Layer 6 has nvib_layer
removing key head.weight from pretrained checkpoint
removing key head.bias from pretrained checkpoint
Pretrained weights found at https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth
number of params: 23740809
Start training for 100 epochs
Epoch: [0]  [   0/2000]  eta: 2:54:41  lr: 0.000001  n_ways: 5  n_imgs: 100  loss: 0.5195 (0.5195)  time: 5.2405  data: 1.4759  max mem: 8392
Epoch: [0]  [  10/2000]  eta: 0:32:22  lr: 0.000001  n_ways: 5  n_imgs: 100  loss: 0.3729 (0.3665)  time: 0.9760  data: 0.1344  max mem: 8519
Epoch: [0]  [  20/2000]  eta: 0:25:05  lr: 0.000001  n_ways: 5  n_imgs: 100  loss: 0.3625 (0.3630)  time: 0.5364  data: 0.0002  max mem: 8519
Epoch: [0]  [  30/2000]  eta: 0:22:26  lr: 0.000001  n_ways: 5  n_imgs: 100  loss: 0.3606 (0.3617)  time: 0.5228  data: 0.0002  max mem: 8519
Epoch: [0]  [  40/2000]  eta: 0:21:02  lr: 0.000001  n_ways: 5  n_imgs: 100  loss: 0.3761 (0.3728)  time: 0.5221  data: 0.0003  max mem: 8519
Epoch: [0]  [  50/2000]  eta: 0:20:08  lr: 0.000001  n_ways: 5  n_imgs: 100  loss: 0.4417 (0.3891)  time: 0.5210  data: 0.0003  max mem: 8519
Epoch: [0]  [  60/2000]  eta: 0:20:05  lr: 0.000001  n_ways: 5  n_imgs: 100  loss: 0.3512 (0.3740)  time: 0.5740  data: 0.0003  max mem: 8519
Epoch: [0]  [  70/2000]  eta: 0:20:06  lr: 0.000001  n_ways: 5  n_imgs: 100  loss: 0.3151 (0.3790)  time: 0.6386  data: 0.0002  max mem: 8519
Epoch: [0]  [  80/2000]  eta: 0:19:40  lr: 0.000001  n_ways: 5  n_imgs: 100  loss: 0.3840 (0.3770)  time: 0.5963  data: 0.0002  max mem: 8519
