Traceback (most recent call last):
  File "/mnt/d/JetBrains/PyCharm 2022.2.3/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/mnt/d/JetBrains/PyCharm 2022.2.3/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/rafa/fs_learning/main.py", line 252, in <module>
    main(args)
  File "/home/rafa/fs_learning/main.py", line 74, in main
    model = get_model(args)
  File "/home/rafa/fs_learning/models/__init__.py", line 240, in get_model
    backbone = get_backbone(args)
  File "/home/rafa/fs_learning/models/__init__.py", line 108, in get_backbone
    model = vit.__dict__['vit_small'](patch_size=16, num_classes=0,drop=args.drop,**nvib_kwargs)
  File "/home/rafa/fs_learning/models/nvib_vision_transformer.py", line 500, in vit_small
    model = NvibVisionTransformer(
  File "/home/rafa/fs_learning/models/nvib_vision_transformer.py", line 363, in __init__
    [
  File "/home/rafa/fs_learning/models/nvib_vision_transformer.py", line 364, in <listcomp>
    Block(
TypeError: models.nvib_vision_transformer.Block() got multiple values for keyword argument 'drop'
Not using distributed mode
Namespace(batch_size=1, num_classes=1000, epochs=100, fp16=False, output_dir='outputs/original_diet_small_lr1e-4', device='cuda:0', seed=0, data_path='/datasets01/imagenet_full_size/061417/', pretrained_checkpoint_path='.', dataset='cifar_fs', nClsEpisode=5, nSupport=5, nQuery=15, nValEpisode=120, nEpisode=2000, image_size=128, base_sources=['aircraft', 'cu_birds', 'dtd', 'fungi', 'ilsvrc_2012', 'omniglot', 'quickdraw', 'vgg_flower'], val_sources=['aircraft', 'cu_birds', 'dtd', 'fungi', 'ilsvrc_2012', 'omniglot', 'quickdraw', 'vgg_flower'], test_sources=['traffic_sign', 'mscoco', 'ilsvrc_2012', 'omniglot', 'aircraft', 'cu_birds', 'dtd', 'quickdraw', 'fungi', 'vgg_flower'], shuffle=True, train_transforms=['random_resized_crop', 'jitter', 'random_flip', 'to_tensor', 'normalize'], test_transforms=['resize', 'center_crop', 'to_tensor', 'normalize'], num_ways=None, num_support=None, num_query=None, min_ways=5, max_ways_upper_bound=50, max_num_query=10, max_support_set_size=500, max_support_size_contrib_per_class=100, min_examples_in_class=0, min_log_weight=-0.6931471805599453, max_log_weight=0.6931471805599453, ignore_bilevel_ontology=False, ignore_dag_ontology=False, ignore_hierarchy_probability=0.0, test_n_way=5, n_shot=5, cdfsl_domains=['EuroSAT', 'ISIC', 'CropDisease', 'ChestX'], arch='deit_small_patch16', patch_size=16, pretrained_weights='', checkpoint_key='teacher', unused_params=False, no_pretrain=False, deploy='vanilla', num_adapters=1, ada_steps=40, ada_lr=0.05, aug_prob=0.9, aug_types=['color', 'translation'], img_size=224, drop=0.1, drop_path=0.1, model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.05, sched='cosine', lr=0.0001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.0, train_interpolation='bicubic', repeated_aug=False, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.0, cutmix=0.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', teacher_model='regnety_160', teacher_path='', distillation_type='none', distillation_alpha=0.5, distillation_tau=1.0, resume='', start_epoch=0, eval=False, dist_eval=False, num_workers=10, pin_mem=True, world_size=1, dist_url='env://', nvib=True, delta=1.0, alpha_tau=0.0, stdev_tau=0.0, lambda_klg=0.001, lambda_kld=0.001, nvib_layers=[0, 1, 2, 3, 4, 5], distributed=False)
Creating model: ProtoNet deit_small_patch16
